<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Just Some Geek</title>
  <subtitle>Yet another geeky blog...</subtitle>
  <id>http://justsomegeek.com</id>
  <link href="http://justsomegeek.com"/>
  <link href="http://justsomegeek.com/feed.xml" rel="self"/>
  <updated>2019-06-18T12:43:00+02:00</updated>
  <author>
    <name>m1n0</name>
  </author>
  <entry>
    <title>ML&amp;#58; Embedding trained model to a website (Titanic pt.4)</title>
    <link rel="alternate" href="http://justsomegeek.com/2019/06/18/ml-embedding-model-website/"/>
    <id>http://justsomegeek.com/2019/06/18/ml-embedding-model-website/</id>
    <published>2019-06-18T12:43:00+02:00</published>
    <updated>2019-06-18T14:45:05+02:00</updated>
    <author>
      <name>m1n0</name>
    </author>
    <summary type="html"> Once we are satisfied with our trained model we might want to embed it somewhere - perhaps brag with it online. We are going to embed our Titanic model to a </summary>
  </entry>
  <entry>
    <title>ML&amp;#58; Feature engineering (Titanic pt.3)</title>
    <link rel="alternate" href="http://justsomegeek.com/2019/06/16/ml-feature-engineering/"/>
    <id>http://justsomegeek.com/2019/06/16/ml-feature-engineering/</id>
    <published>2019-06-16T22:02:00+02:00</published>
    <updated>2019-06-18T10:37:47+02:00</updated>
    <author>
      <name>m1n0</name>
    </author>
    <summary type="html"> Another technique we previously mentioned that can be used to try making our predictions better is Feature Engineering. In todays article we will take a look </summary>
  </entry>
  <entry>
    <title>Slack desktop dark theme</title>
    <link rel="alternate" href="http://justsomegeek.com/2019/06/14/slack-desktop-dark-theme/"/>
    <id>http://justsomegeek.com/2019/06/14/slack-desktop-dark-theme/</id>
    <published>2019-06-14T10:37:00+02:00</published>
    <updated>2019-06-14T11:26:41+02:00</updated>
    <author>
      <name>m1n0</name>
    </author>
    <summary type="html"> If you love dark themes everywhere as much as I do, you surely have been wondering why Slack still does not support one. 

 Here is a quick tutorial how to use </summary>
  </entry>
  <entry>
    <title>ML&amp;#58; Encoding features and classifier performance (Titanic pt.2)</title>
    <link rel="alternate" href="http://justsomegeek.com/2019/05/11/ml-encoding-features-classifier-performance/"/>
    <id>http://justsomegeek.com/2019/05/11/ml-encoding-features-classifier-performance/</id>
    <published>2019-05-11T21:52:00+02:00</published>
    <updated>2019-06-17T14:56:59+02:00</updated>
    <author>
      <name>m1n0</name>
    </author>
    <summary type="html"> As we previously mentioned, we will be looking into making our simplest classifier model better. One of the commonly used techniques used is categorical feature </summary>
  </entry>
  <entry>
    <title>Why and how I started learning Python and Machine Learning pt.2</title>
    <link rel="alternate" href="http://justsomegeek.com/2019/04/16/why-and-how-i-started-learning-python-and-machine-learning-pt-2/"/>
    <id>http://justsomegeek.com/2019/04/16/why-and-how-i-started-learning-python-and-machine-learning-pt-2/</id>
    <published>2019-04-16T20:41:00+02:00</published>
    <updated>2019-04-18T10:52:38+02:00</updated>
    <author>
      <name>m1n0</name>
    </author>
    <summary type="html"> It has been over a year since I decided to document my python/ML/Data Science learning path online a bit. A lot has happened in the meantime, especially in my </summary>
  </entry>
  <entry>
    <title>ML&amp;#58; Building a simple classifier (Titanic pt.1)</title>
    <link rel="alternate" href="http://justsomegeek.com/2019/03/14/ml-building-basic-classifier/"/>
    <id>http://justsomegeek.com/2019/03/14/ml-building-basic-classifier/</id>
    <published>2019-03-14T21:52:00+01:00</published>
    <updated>2019-04-23T12:35:06+02:00</updated>
    <author>
      <name>m1n0</name>
    </author>
    <summary type="html"> Learning Machine Learning is an intimidating task - there is simply way too much to learn, too many tools, technologies and techniques to grasp. On the other </summary>
  </entry>
</feed>
